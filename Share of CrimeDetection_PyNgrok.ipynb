{"cells":[{"cell_type":"code","source":["!pip -q install pyngrok"],"metadata":{"id":"ejNzY876XBzt","executionInfo":{"status":"ok","timestamp":1742611429908,"user_tz":-420,"elapsed":4487,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","UCF Crime Detection - Video Processing and Inference\n","Author: matapv01\n","Created: 2025-03-15 09:27:27\n","\"\"\"\n","import os\n","import cv2\n","import torch\n","import numpy as np\n","from tqdm import tqdm\n","from PIL import Image\n","import torch.nn as nn\n","from datetime import datetime\n","from torchvision import transforms\n","from transformers import ViTImageProcessor, ViTForImageClassification\n","from huggingface_hub import login\n","from IPython.display import HTML\n","from base64 import b64encode\n","from google.colab import files\n","# Install required packages\n","!pip install transformers torch torchvision opencv-python pillow tqdm\n","import cv2\n","from IPython.display import HTML\n","from base64 import b64encode\n","from transformers import ViTForImageClassification, ViTImageProcessor\n","import torch\n","# Load model\n","# Import the necessary modules\n","from huggingface_hub import login, HfApi\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIMvYwrK64Xy","executionInfo":{"status":"ok","timestamp":1742611463921,"user_tz":-420,"elapsed":34007,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}},"outputId":"529cf3b6-e10c-40f5-ddaf-0ce50403a813"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"]}]},{"cell_type":"code","source":["# Hugging Face settings\n","MODEL_ID_2 = \"mata01/crime-20frame-detection-vit-model\"  # Your model repo name\n","#HF_TOKEN = \"hf_xxx\"  # Replace with your token\n","from google.colab import userdata\n","HF_TOKEN = userdata.get('HF_TOKEN')\n","token = HF_TOKEN\n","\n","if HF_TOKEN:\n","  print(f\"Loaded token success\")\n"],"metadata":{"id":"iztEsLAQgc-9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742611464500,"user_tz":-420,"elapsed":576,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}},"outputId":"802c3ea1-33da-4b18-822c-3d7b7b92f146"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded token success\n"]}]},{"cell_type":"code","source":["# Constants\n","FRAME_CHUNK_SIZE = 20\n","BATCH_SIZE = 32\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Label mapping\n","LABELS = {\n","    0: \"Abuse\", 1: \"Arrest\", 2: \"Arson\", 3: \"Assault\",\n","    4: \"Burglary\", 5: \"Explosion\", 6: \"Fighting\", 7: \"Normal\",\n","    8: \"Road Accident\", 9: \"Robbery\", 10: \"Shooting\",\n","    11: \"Shoplifting\", 12: \"Stealing\", 13: \"Vandalism\"\n","}\n","\n","class VideoProcessor:\n","    def __init__(self):\n","        print(\"Loading model from Hugging Face...\")\n","        # Initialize video properties\n","        self.fps = None\n","        self.frame_width = None\n","        self.frame_height = None\n","\n","        try:\n","            # Login to Hugging Face\n","            login(HF_TOKEN)\n","\n","            # Load model and processor\n","            self.model = ViTForImageClassification.from_pretrained(\n","                MODEL_ID_2,\n","                use_auth_token=HF_TOKEN,\n","                num_labels=len(LABELS),\n","                id2label=LABELS\n","            ).to(DEVICE)\n","\n","            self.processor = ViTImageProcessor.from_pretrained(\n","                MODEL_ID_2,\n","                use_auth_token=HF_TOKEN\n","            )\n","\n","            print(\"Model loaded successfully!\")\n","\n","        except Exception as e:\n","            print(f\"Error loading from Hugging Face: {str(e)}\")\n","            raise\n","\n","        self.model.eval()\n","\n","        self.transform = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225]\n","            )\n","        ])\n","\n","    def extract_frames(self, video_path):\n","        print(\"Extracting frames from video...\")\n","        frames = []\n","        cap = cv2.VideoCapture(video_path)\n","\n","        if not cap.isOpened():\n","            raise ValueError(f\"Could not open video file: {video_path}\")\n","\n","        # Get video properties\n","        self.fps = int(cap.get(cv2.CAP_PROP_FPS))\n","        self.frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        self.frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","        print(f\"Video properties: {self.fps} FPS, {self.frame_width}x{self.frame_height}\")\n","\n","        for _ in tqdm(range(total_frames), desc=\"Extracting frames\"):\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            frames.append(frame)\n","\n","        cap.release()\n","        return frames\n","\n","    def create_frame_chunks(self, frames):\n","        print(\"Creating frame chunks...\")\n","        chunks = []\n","        for i in range(0, len(frames), FRAME_CHUNK_SIZE):\n","            chunk = frames[i:i + FRAME_CHUNK_SIZE]\n","            if len(chunk) == FRAME_CHUNK_SIZE:  # Only use complete chunks\n","                chunks.append(chunk)\n","        return chunks\n","\n","    def process_chunk(self, chunk):\n","        processed_frames = []\n","        for frame in chunk:\n","            pil_image = Image.fromarray(frame)\n","            processed_frame = self.transform(pil_image)\n","            processed_frames.append(processed_frame)\n","\n","        batch = torch.stack(processed_frames).to(DEVICE)\n","\n","        with torch.no_grad():\n","            outputs = self.model(batch)\n","            predictions = torch.softmax(outputs.logits, dim=-1)\n","            chunk_pred = predictions.mean(dim=0)\n","            label_idx = chunk_pred.argmax().item()\n","            confidence = chunk_pred[label_idx].item()\n","\n","        return LABELS[label_idx], confidence\n","\n","    def create_output_video(self, frames, predictions, output_path):\n","        print(\"Creating output video...\")\n","        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","        out = cv2.VideoWriter(output_path, fourcc, self.fps,\n","                            (self.frame_width, self.frame_height))\n","\n","        # Create mapping from frame index to prediction\n","        frame_predictions = {}\n","        for chunk_idx, (label, conf) in enumerate(predictions):\n","            start_frame = chunk_idx * FRAME_CHUNK_SIZE\n","            end_frame = start_frame + FRAME_CHUNK_SIZE\n","            for frame_idx in range(start_frame, end_frame):\n","                frame_predictions[frame_idx] = (label, conf)\n","\n","        print(\"Adding labels to frames...\")\n","        for frame_idx, frame in enumerate(tqdm(frames, desc=\"Processing frames\")):\n","            if frame_idx in frame_predictions:\n","                label, conf = frame_predictions[frame_idx]\n","\n","                # Create copy of frame\n","                frame = frame.copy()\n","\n","                # Text to display\n","                text = f\"Action: {label} ({conf:.2f})\"\n","\n","                # Draw black background\n","                (text_width, text_height), _ = cv2.getTextSize(\n","                    text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2\n","                )\n","                cv2.rectangle(\n","                    frame,\n","                    (10, 10),\n","                    (text_width + 20, 40),\n","                    (0, 0, 0),\n","                    -1\n","                )\n","\n","                # Draw white text\n","                cv2.putText(\n","                    frame,\n","                    text,\n","                    (15, 30),\n","                    cv2.FONT_HERSHEY_SIMPLEX,\n","                    1,\n","                    (255, 255, 255),\n","                    2,\n","                    cv2.LINE_AA\n","                )\n","\n","            # Write frame\n","            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n","            out.write(frame_bgr)\n","\n","        out.release()\n","        print(f\"Video saved to {output_path}\")\n","\n","    def process_video(self, input_path, output_path = 'static/outputs/video.mp4'):\n","        try:\n","            # Extract frames\n","            frames = self.extract_frames(input_path)\n","            if not frames:\n","                raise ValueError(\"No frames extracted from video\")\n","\n","            print(f\"Total frames: {len(frames)}\")\n","\n","            # Create and process chunks\n","            chunks = self.create_frame_chunks(frames)\n","            print(f\"Total chunks: {len(chunks)}\")\n","\n","            # Process chunks\n","            print(\"Processing chunks...\")\n","            predictions = []\n","            for chunk in tqdm(chunks, desc=\"Processing chunks\"):\n","                label, confidence = self.process_chunk(chunk)\n","                predictions.append((label, confidence))\n","\n","            # Create output video\n","            print(\"\\nCreating output video...\")\n","            self.create_output_video(frames, predictions, output_path)\n","\n","            return output_path\n","\n","        except Exception as e:\n","            print(f\"Error processing video: {str(e)}\")\n","            return\n","\n","def show_video(video_path):\n","    \"\"\"\n","    Displays a video in the notebook\n","    \"\"\"\n","    mp4 = open(video_path, 'rb').read()\n","    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","    return HTML(f\"\"\"\n","    <video width=600 controls>\n","        <source src=\"{data_url}\" type=\"video/mp4\">\n","    </video>\n","    \"\"\")"],"metadata":{"id":"UEq9VTa0gek_","executionInfo":{"status":"ok","timestamp":1742611464547,"user_tz":-420,"elapsed":35,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def loadimgprocessor():\n","  # Định nghĩa repository ID\n","  username = \"mata01\"  # Thay bằng username thật của bạn\n","  model_name = \"crime_action_cctv_image_detection\"\n","  repo_id = f\"{username}/{model_name}\"\n","\n","  # Tải mô hình và tiền xử lý từ Hugging Face Model Hub\n","  model = ViTForImageClassification.from_pretrained(repo_id, token=token)\n","  processor = ViTImageProcessor.from_pretrained(repo_id, token=token)\n","\n","  # 1. Kiểm tra và chọn thiết bị (GPU nếu có)\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  print(f\"Using device: {device}\")\n","\n","  # Chuyển mô hình sang GPU\n","  model.to(device)\n","  model.eval()  # Đặt mô hình ở chế độ evaluation để tối ưu suy luận\n","  print(\"Model moved to GPU successfully!\")\n","  return model, processor\n","\n","from PIL import Image, ImageDraw, ImageFont\n","import os\n","\n","def predict_image(image_path, output_path='static/outputs/output_image.jpg'):\n","    try:\n","        # Đọc ảnh sử dụng OpenCV\n","        img = cv2.imread(image_path)\n","        if img is None:\n","            print(f\"Lỗi: Không thể đọc ảnh tại {image_path}\")\n","            return\n","\n","        # Chuyển đổi ảnh sang RGB\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        # Tiền xử lý ảnh\n","        inputs = processor_img(images=img, return_tensors=\"pt\").to(device)\n","\n","        # Dự đoán\n","        with torch.no_grad():\n","            outputs = model_img(**inputs)\n","            logits = outputs.logits\n","            predicted_class_id = logits.argmax().item()\n","            predicted_label = model_img.config.id2label[predicted_class_id]\n","\n","        # Hiển thị ảnh với nhãn dự đoán\n","        pil_img = Image.fromarray(img)\n","        draw = ImageDraw.Draw(pil_img)\n","        font_size = 30\n","        font = ImageFont.truetype(\"LiberationSansNarrow-Bold.ttf\", font_size)\n","        text_position = (10, 10)\n","        text_color = (255, 0, 0)\n","\n","        # Vẽ nhãn dự đoán lên ảnh\n","        draw.text(text_position, predicted_label, fill=text_color, font=font)\n","\n","        # Lưu ảnh đầu ra\n","        pil_img.save(output_path)\n","        return output_path\n","\n","    except Exception as e:\n","        import traceback\n","        traceback.print_exc()\n","        print(f\"Đã xảy ra lỗi: {e}\")\n","        return"],"metadata":{"id":"w52jXxCWgg89","executionInfo":{"status":"ok","timestamp":1742611464556,"user_tz":-420,"elapsed":10,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Khởi tạo các model AI\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Loading models...\")\n","processor = VideoProcessor()\n","model_img, processor_img = loadimgprocessor()\n","print(\"Models loaded successfully!\")"],"metadata":{"id":"NEmsa7vwghvp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742611465457,"user_tz":-420,"elapsed":899,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}},"outputId":"a9965e6c-6258-422b-c667-5f527411d128"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading models...\n","Loading model from Hugging Face...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3513: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/image_processing_base.py:196: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n","Using device: cpu\n","Model moved to GPU successfully!\n","Models loaded successfully!\n"]}]},{"cell_type":"code","source":["!mkdir -p templates\n","with open(\"templates/index.html\", \"w\") as f:\n","    f.write(\"\"\"\n","    <!DOCTYPE html>\n","    <html lang=\"vi\">\n","    <head>\n","        <meta charset=\"UTF-8\">\n","        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n","        <title>AI Crime Detection</title>\n","        <link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n","        <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\" rel=\"stylesheet\">\n","    </head>\n","    <body class=\"bg-gray-100 min-h-screen flex flex-col items-center justify-center p-6\">\n","        <header class=\"text-center mb-6\">\n","            <h1 class=\"text-4xl font-bold text-gray-800\">AI Crime Detection</h1>\n","            <p class=\"text-gray-600\">Phân tích hành vi đáng ngờ từ ảnh và video</p>\n","        </header>\n","        <div class=\"bg-white p-6 rounded-lg shadow-lg max-w-xl w-full\">\n","            <div class=\"flex justify-center space-x-4 mb-6\">\n","                <button id=\"image-tab\" class=\"tab-btn bg-blue-500 text-white\">\n","                    <i class=\"fas fa-image mr-2\"></i> Ảnh\n","                </button>\n","                <button id=\"video-tab\" class=\"tab-btn bg-gray-500 text-white\">\n","                    <i class=\"fas fa-video mr-2\"></i> Video\n","                </button>\n","            </div>\n","            <div id=\"image-section\" class=\"upload-section\">\n","                <label for=\"image-input\" class=\"upload-label\">\n","                    <i class=\"fas fa-cloud-upload-alt text-4xl text-gray-400\"></i>\n","                    <p>Chọn ảnh để phân tích</p>\n","                </label>\n","                <input type=\"file\" id=\"image-input\" accept=\"image/*\" class=\"hidden\">\n","            </div>\n","            <div id=\"video-section\" class=\"upload-section hidden\">\n","                <label for=\"video-input\" class=\"upload-label\">\n","                    <i class=\"fas fa-cloud-upload-alt text-4xl text-gray-400\"></i>\n","                    <p>Chọn video để phân tích</p>\n","                </label>\n","                <input type=\"file\" id=\"video-input\" accept=\"video/*\" class=\"hidden\">\n","            </div>\n","            <div id=\"loading\" class=\"hidden text-center py-4\">\n","                <div class=\"animate-spin rounded-full h-12 w-12 border-b-2 border-blue-500 mx-auto mb-4\"></div>\n","                <p class=\"text-gray-600\">Đang xử lý...</p>\n","            </div>\n","            <div id=\"preview\" class=\"hidden\">\n","                <h2 class=\"text-lg font-semibold text-center mb-4\">Kết quả phân tích</h2>\n","                <div class=\"grid grid-cols-2 gap-4\">\n","                    <div>\n","                        <h3 class=\"text-sm font-medium\">File gốc</h3>\n","                        <img id=\"original-image\" class=\"preview-img hidden\">\n","                        <video id=\"original-video\" class=\"preview-video hidden\" controls type=\"video/mp4\"></video>\n","                    </div>\n","                    <div>\n","                        <h3 class=\"text-sm font-medium\">Kết quả</h3>\n","                        <img id=\"result-image\" class=\"preview-img hidden\">\n","                        <div class=\"mt-8\"> <!-- Thêm div để tạo khoảng cách -->\n","                            <a id=\"result-video-download\" class=\"hidden bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600\" href=\"#\" download>Tải video kết quả</a>\n","                        </div>\n","                    </div>\n","                </div>\n","            </div>\n","        </div>\n","        <script>\n","            document.addEventListener('DOMContentLoaded', function() {\n","                const tabs = {\n","                    image: document.getElementById('image-tab'),\n","                    video: document.getElementById('video-tab')\n","                };\n","                const sections = {\n","                    image: document.getElementById('image-section'),\n","                    video: document.getElementById('video-section')\n","                };\n","                const inputs = {\n","                    image: document.getElementById('image-input'),\n","                    video: document.getElementById('video-input')\n","                };\n","                const preview = document.getElementById('preview');\n","                const loading = document.getElementById('loading');\n","                const originalImage = document.getElementById('original-image');\n","                const originalVideo = document.getElementById('original-video');\n","                const resultImage = document.getElementById('result-image');\n","                const resultVideoDownload = document.getElementById('result-video-download');\n","\n","                function switchTab(type) {\n","                    Object.keys(tabs).forEach(key => {\n","                        tabs[key].classList.toggle('bg-blue-500', key === type);\n","                        tabs[key].classList.toggle('bg-gray-500', key !== type);\n","                        sections[key].classList.toggle('hidden', key !== type);\n","                    });\n","                }\n","\n","                tabs.image.addEventListener('click', () => switchTab('image'));\n","                tabs.video.addEventListener('click', () => switchTab('video'));\n","\n","                async function uploadFile(file, type) {\n","                    preview.classList.remove('hidden');\n","                    loading.classList.remove('hidden');\n","                    resultImage.classList.add('hidden');\n","                    resultVideoDownload.classList.add('hidden');\n","\n","                    const url = URL.createObjectURL(file);\n","                    if (type === 'image') {\n","                        originalImage.src = url;\n","                        originalImage.classList.remove('hidden');\n","                        originalVideo.classList.add('hidden');\n","                    } else {\n","                        originalVideo.src = url;\n","                        originalVideo.classList.remove('hidden');\n","                        originalImage.classList.add('hidden');\n","                    }\n","\n","                    const formData = new FormData();\n","                    formData.append('file', file);\n","\n","                    try {\n","                        const endpoint = type === 'image' ? '/upload/image' : '/upload/video';\n","                        console.log('Requesting:', window.location.origin + endpoint);\n","                        const response = await fetch(endpoint, {\n","                            method: 'POST',\n","                            body: formData\n","                        });\n","\n","                        const responseText = await response.text();\n","                        console.log('Response status:', response.status);\n","                        console.log('Response text:', responseText);\n","\n","                        if (!response.ok) {\n","                            throw new Error(`Server responded with ${response.status}: ${responseText}`);\n","                        }\n","\n","                        const data = JSON.parse(responseText);\n","                        if (data.error) {\n","                            throw new Error(data.error);\n","                        }\n","\n","                        const fullOutputUrl = window.location.origin + data.output_url;\n","                        if (type === 'image') {\n","                            console.log('Setting image src to:', fullOutputUrl);\n","                            resultImage.src = fullOutputUrl;\n","                            resultImage.classList.remove('hidden');\n","                        } else {\n","                            console.log('Setting video download link to:', fullOutputUrl);\n","                            resultVideoDownload.href = fullOutputUrl;\n","                            resultVideoDownload.classList.remove('hidden');\n","                        }\n","\n","                        loading.classList.add('hidden');\n","                    } catch (error) {\n","                        console.error('Error:', error);\n","                        alert(`Upload failed: ${error.message}`);\n","                        loading.classList.add('hidden');\n","                    }\n","                }\n","\n","                inputs.image.addEventListener('change', event => {\n","                    if (event.target.files[0]) uploadFile(event.target.files[0], 'image');\n","                });\n","                inputs.video.addEventListener('change', event => {\n","                    if (event.target.files[0]) uploadFile(event.target.files[0], 'video');\n","                });\n","            });\n","        </script>\n","        <style>\n","            .tab-btn { padding: 10px 20px; border-radius: 8px; transition: 0.3s; }\n","            .upload-section { text-align: center; padding: 20px; border: 2px dashed #ccc; border-radius: 8px; cursor: pointer; }\n","            .upload-label { display: block; padding: 30px; cursor: pointer; }\n","            .preview-img, .preview-video { width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }\n","        </style>\n","    </body>\n","    </html>\n","    \"\"\")"],"metadata":{"id":"tXRQHQ-rTOlY","executionInfo":{"status":"ok","timestamp":1742611465596,"user_tz":-420,"elapsed":138,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, request, render_template, send_file, jsonify\n","import numpy as np\n","import os\n","from pyngrok import ngrok, conf # Import conf from pyngrok\n","# lấy token ngrok từ secrectkey\n","from google.colab import userdata\n","conf.get_default().auth_token = userdata.get('ngrok_token')\n","\n","\n","# Khởi tạo Flask app\n","app = Flask(__name__)\n","UPLOAD_FOLDER = \"static/uploads\"\n","OUTPUT_FOLDER = \"static/outputs\"\n","os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n","os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n","\n","# kết nối sever ngrok để tọa tunnel\n","public_url = ngrok.connect(8888).public_url\n","print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 8888))\n","\n","# Route chính\n","@app.route('/')\n","def index():\n","    print(\"Rendering index.html\")\n","    return render_template('index.html')\n","\n","# Route upload ảnh\n","@app.route('/upload/image', methods=['POST'])\n","def upload_image():\n","    print(\"Received request to /upload/image\")\n","    try:\n","        if 'file' not in request.files:\n","            print(\"No file part in request\")\n","            return jsonify({'error': 'No file part in request'}), 400\n","\n","        file = request.files['file']\n","        if file.filename == '':\n","            print(\"No file selected\")\n","            return jsonify({'error': 'No file selected'}), 400\n","\n","        file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n","        print(f\"Saving file to: {file_path}\")\n","        file.save(file_path)\n","\n","        output_path = predict_image(file_path)\n","        output_url = f\"/outputs/{os.path.basename(output_path)}\"\n","        print(f\"Returning JSON: {{'output_url': '{output_url}'}}\")\n","\n","        return jsonify({'output_url': output_url})\n","    except Exception as e:\n","        print(f\"Error in upload_image: {str(e)}\")\n","        return jsonify({'error': str(e)}), 500\n","\n","# Route upload video\n","@app.route('/upload/video', methods=['POST'])\n","def upload_video():\n","    print(\"Received request to /upload/video\")\n","    try:\n","        if 'file' not in request.files:\n","            print(\"No file part in request\")\n","            return jsonify({'error': 'No file part in request'}), 400\n","\n","        file = request.files['file']\n","        if file.filename == '':\n","            print(\"No file selected\")\n","            return jsonify({'error': 'No file selected'}), 400\n","\n","        file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n","        print(f\"Saving file to: {file_path}\")\n","        file.save(file_path)\n","\n","        output_path = processor.process_video(file_path)\n","        output_url = f\"/outputs/{os.path.basename(output_path)}\"\n","        print(f\"Returning JSON: {{'output_url': '{output_url}'}}\")\n","\n","        return jsonify({'output_url': output_url})\n","    except Exception as e:\n","        print(f\"Error in upload_video: {str(e)}\")\n","        return jsonify({'error': str(e)}), 500\n","\n","# Route phục vụ file\n","@app.route('/outputs/<path:filename>')\n","def serve_output(filename):\n","    print(f\"Serving file: {filename}\")\n","    file_path = os.path.join(OUTPUT_FOLDER, filename)\n","    if not os.path.exists(file_path):\n","        print(\"File not found\")\n","        return jsonify({'error': 'Output file not found'}), 404\n","\n","    # Gửi file (ảnh hoặc video) để xem hoặc tải\n","    return send_file(file_path, as_attachment=False, conditional=True)\n","\n","if __name__ == '__main__':\n","    app.run(debug=True, host='0.0.0.0', port=8888, use_reloader=False)"],"metadata":{"id":"MqUx4MuPU4jF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01486a1e-3c2c-4bf2-bc9e-f1a410897957","executionInfo":{"status":"ok","timestamp":1742611997955,"user_tz":-420,"elapsed":532355,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" * ngrok tunnel \"https://51e4-34-75-135-253.ngrok-free.app\" -> \"http://127.0.0.1:8888/\"\n"," * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:8888\n"," * Running on http://172.28.0.12:8888\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 02:45:07] \"GET / HTTP/1.1\" 200 -\n"]},{"output_type":"stream","name":"stdout","text":["Rendering index.html\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 02:45:17] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"]},{"output_type":"stream","name":"stdout","text":["Received request to /upload/video\n","Saving file to: static/uploads/output_video_action.mp4\n","Extracting frames from video...\n","Video properties: 30 FPS, 1280x720\n"]},{"output_type":"stream","name":"stderr","text":["Extracting frames: 100%|██████████| 436/436 [00:03<00:00, 136.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Total frames: 436\n","Creating frame chunks...\n","Total chunks: 21\n","Processing chunks...\n"]},{"output_type":"stream","name":"stderr","text":["Processing chunks: 100%|██████████| 21/21 [05:01<00:00, 14.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Creating output video...\n","Creating output video...\n","Adding labels to frames...\n"]},{"output_type":"stream","name":"stderr","text":["Processing frames: 100%|██████████| 436/436 [00:03<00:00, 121.70it/s]\n","INFO:werkzeug:127.0.0.1 - - [22/Mar/2025 02:50:44] \"POST /upload/video HTTP/1.1\" 200 -\n"]},{"output_type":"stream","name":"stdout","text":["Video saved to static/outputs/video.mp4\n","Returning JSON: {'output_url': '/outputs/video.mp4'}\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"wthaaplxQHX7","executionInfo":{"status":"ok","timestamp":1742611997958,"user_tz":-420,"elapsed":39,"user":{"displayName":"Minh Phạm Văn","userId":"09034337405395880200"}}},"outputs":[],"source":["# import getpass\n","# import os\n","# import threading\n","\n","# from flask import Flask\n","\n","\n","# print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n","\n","\n","\n","# app = Flask(__name__)\n","\n","# # Open a ngrok tunnel to the HTTP server\n","# public_url = ngrok.connect(5000).public_url\n","# print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 5000))\n","\n","# # Update any base URLs to use the public ngrok URL\n","# app.config[\"BASE_URL\"] = public_url\n","\n","# # ... Update inbound traffic via APIs to use the public-facing ngrok URL\n","\n","\n","# # Define Flask routes\n","# @app.route(\"/\")\n","# def index():\n","#     return \"Hello from Colab!\"\n","\n","# # # Start the Flask server in a new thread\n","# # threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()\n","# app.run()\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}